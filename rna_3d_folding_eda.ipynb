{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud83e\uddec Stanford RNA 3D Folding Part 2 - EDA & Visualisation 3D\n",
        "\n",
        "Ce notebook explore les donn\u00e9es du concours Stanford RNA 3D Folding Part 2.\n",
        "\n",
        "**Objectif** : Pr\u00e9dire la structure 3D de mol\u00e9cules d'ARN \u00e0 partir de leur s\u00e9quence.\n",
        "\n",
        "**Sections** :\n",
        "1. Chargement des donn\u00e9es\n",
        "2. Analyse exploratoire des s\u00e9quences\n",
        "3. Analyse des labels (coordonn\u00e9es 3D)\n",
        "4. Visualisation 3D des structures RNA\n",
        "5. Analyse des MSA (Multiple Sequence Alignments)\n",
        "6. Exploration des m\u00e9tadonn\u00e9es\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udce6 1. Imports et Configuration\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np",
        "import pandas as pd",
        "import matplotlib.pyplot as plt",
        "import seaborn as sns",
        "from pathlib import Path",
        "import warnings",
        "from collections import Counter",
        "from Bio import SeqIO  # Pour parser les fichiers FASTA",
        "import plotly.graph_objects as go",
        "import plotly.express as px",
        "from plotly.subplots import make_subplots",
        "",
        "warnings.filterwarnings('ignore')",
        "plt.style.use('seaborn-v0_8-whitegrid')",
        "",
        "# Configuration des couleurs pour les nucl\u00e9otides",
        "NUCLEOTIDE_COLORS = {",
        "    'A': '#FF6B6B',  # Rouge - Ad\u00e9nine",
        "    'U': '#4ECDC4',  # Cyan - Uracile",
        "    'G': '#45B7D1',  # Bleu - Guanine",
        "    'C': '#96CEB4',  # Vert - Cytosine",
        "}",
        "",
        "# Chemin vers les donn\u00e9es (ajuster selon l'environnement Kaggle)",
        "DATA_PATH = Path('/kaggle/input/stanford-rna-3d-folding-2')",
        "",
        "print(\"\ud83d\udcc1 Structure des donn\u00e9es:\")",
        "print(f\"  - MSA/: {len(list((DATA_PATH / 'MSA').glob('*.fasta')))} fichiers\")",
        "print(f\"  - PDB_RNA/: {len(list((DATA_PATH / 'PDB_RNA').glob('*.cif')))} fichiers\")",
        ""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcca 2. Chargement des Donn\u00e9es\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Chargement des fichiers CSV principaux",
        "train_sequences = pd.read_csv(DATA_PATH / 'train_sequences.csv')",
        "validation_sequences = pd.read_csv(DATA_PATH / 'validation_sequences.csv')",
        "test_sequences = pd.read_csv(DATA_PATH / 'test_sequences.csv')",
        "",
        "train_labels = pd.read_csv(DATA_PATH / 'train_labels.csv')",
        "validation_labels = pd.read_csv(DATA_PATH / 'validation_labels.csv')",
        "",
        "sample_submission = pd.read_csv(DATA_PATH / 'sample_submission.csv')",
        "",
        "# M\u00e9tadonn\u00e9es",
        "rna_metadata = pd.read_csv(DATA_PATH / 'extra' / 'rna_metadata.csv')",
        "",
        "print(\"=\" * 60)",
        "print(\"\ud83d\udccb R\u00c9SUM\u00c9 DES DONN\u00c9ES\")",
        "print(\"=\" * 60)",
        "print(f\"\\n\ud83d\udd39 S\u00e9quences:\")",
        "print(f\"   Train:       {len(train_sequences):,} s\u00e9quences\")",
        "print(f\"   Validation:  {len(validation_sequences):,} s\u00e9quences\")",
        "print(f\"   Test:        {len(test_sequences):,} s\u00e9quences\")",
        "print(f\"\\n\ud83d\udd39 Labels (coordonn\u00e9es 3D):\")",
        "print(f\"   Train:       {len(train_labels):,} r\u00e9sidus\")",
        "print(f\"   Validation:  {len(validation_labels):,} r\u00e9sidus\")",
        "print(f\"\\n\ud83d\udd39 M\u00e9tadonn\u00e9es: {len(rna_metadata):,} entr\u00e9es\")",
        ""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud83d\udd2c 3. Analyse des S\u00e9quences\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Structure des donn\u00e9es de s\u00e9quences\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"\ud83d\udccb Colonnes train_sequences:\")\n",
        "print(train_sequences.columns.tolist())\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "train_sequences.head(3)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Aper\u00e7u d\u00e9taill\u00e9 d'une s\u00e9quence",
        "print(\"\ud83d\udd0d Exemple de s\u00e9quence (premi\u00e8re entr\u00e9e):\")",
        "print(\"-\" * 60)",
        "for col in train_sequences.columns:",
        "    val = train_sequences.iloc[0][col]",
        "    if isinstance(val, str) and len(val) > 100:",
        "        print(f\"{col}: {val[:100]}...\")",
        "    else:",
        "        print(f\"{col}: {val}\")",
        ""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Distribution des longueurs de s\u00e9quences\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculer les longueurs",
        "train_sequences['seq_length'] = train_sequences['sequence'].str.len()",
        "validation_sequences['seq_length'] = validation_sequences['sequence'].str.len()",
        "test_sequences['seq_length'] = test_sequences['sequence'].str.len()",
        "",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))",
        "",
        "# Train",
        "axes[0].hist(train_sequences['seq_length'], bins=50, color='steelblue', alpha=0.7, edgecolor='black')",
        "axes[0].set_title(f'Train (n={len(train_sequences):,})', fontsize=12, fontweight='bold')",
        "axes[0].set_xlabel('Longueur de s\u00e9quence')",
        "axes[0].set_ylabel('Fr\u00e9quence')",
        "axes[0].axvline(train_sequences['seq_length'].median(), color='red', linestyle='--', label=f\"M\u00e9diane: {train_sequences['seq_length'].median():.0f}\")",
        "axes[0].legend()",
        "",
        "# Validation",
        "axes[1].hist(validation_sequences['seq_length'], bins=30, color='seagreen', alpha=0.7, edgecolor='black')",
        "axes[1].set_title(f'Validation (n={len(validation_sequences):,})', fontsize=12, fontweight='bold')",
        "axes[1].set_xlabel('Longueur de s\u00e9quence')",
        "axes[1].axvline(validation_sequences['seq_length'].median(), color='red', linestyle='--', label=f\"M\u00e9diane: {validation_sequences['seq_length'].median():.0f}\")",
        "axes[1].legend()",
        "",
        "# Test",
        "axes[2].hist(test_sequences['seq_length'], bins=30, color='coral', alpha=0.7, edgecolor='black')",
        "axes[2].set_title(f'Test (n={len(test_sequences):,})', fontsize=12, fontweight='bold')",
        "axes[2].set_xlabel('Longueur de s\u00e9quence')",
        "axes[2].axvline(test_sequences['seq_length'].median(), color='red', linestyle='--', label=f\"M\u00e9diane: {test_sequences['seq_length'].median():.0f}\")",
        "axes[2].legend()",
        "",
        "plt.suptitle('\ud83d\udcca Distribution des Longueurs de S\u00e9quences RNA', fontsize=14, fontweight='bold', y=1.02)",
        "plt.tight_layout()",
        "plt.show()",
        "",
        "# Statistiques",
        "print(\"\\n\ud83d\udcc8 Statistiques des longueurs:\")",
        "print(\"-\" * 60)",
        "for name, df in [('Train', train_sequences), ('Validation', validation_sequences), ('Test', test_sequences)]:",
        "    print(f\"{name:12} | Min: {df['seq_length'].min():5} | Max: {df['seq_length'].max():5} | \"",
        "          f\"Mean: {df['seq_length'].mean():7.1f} | Median: {df['seq_length'].median():6.0f}\")",
        ""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Composition en nucl\u00e9otides\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def analyze_nucleotide_composition(sequences, name):",
        "    \"\"\"Analyse la composition en nucl\u00e9otides d'un ensemble de s\u00e9quences.\"\"\"",
        "    all_nucleotides = ''.join(sequences['sequence'].values)",
        "    counts = Counter(all_nucleotides)",
        "    total = sum(counts.values())",
        "",
        "    composition = {nt: (count / total) * 100 for nt, count in counts.items()}",
        "    return composition",
        "",
        "# Analyser chaque dataset",
        "compositions = {}",
        "for name, df in [('Train', train_sequences), ('Validation', validation_sequences), ('Test', test_sequences)]:",
        "    compositions[name] = analyze_nucleotide_composition(df, name)",
        "",
        "# Visualisation",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))",
        "",
        "for idx, (name, comp) in enumerate(compositions.items()):",
        "    nucleotides = ['A', 'U', 'G', 'C']",
        "    values = [comp.get(nt, 0) for nt in nucleotides]",
        "    colors = [NUCLEOTIDE_COLORS[nt] for nt in nucleotides]",
        "",
        "    bars = axes[idx].bar(nucleotides, values, color=colors, edgecolor='black', linewidth=1.5)",
        "    axes[idx].set_title(f'{name}', fontsize=12, fontweight='bold')",
        "    axes[idx].set_ylabel('Pourcentage (%)')",
        "    axes[idx].set_ylim(0, 35)",
        "",
        "    # Ajouter les valeurs sur les barres",
        "    for bar, val in zip(bars, values):",
        "        axes[idx].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,",
        "                      f'{val:.1f}%', ha='center', fontsize=10, fontweight='bold')",
        "",
        "plt.suptitle('\ud83e\uddec Composition en Nucl\u00e9otides (A, U, G, C)', fontsize=14, fontweight='bold', y=1.02)",
        "plt.tight_layout()",
        "plt.show()",
        "",
        "# Autres nucl\u00e9otides (modifications)",
        "print(\"\\n\ud83d\udd2c Nucl\u00e9otides non-canoniques d\u00e9tect\u00e9s:\")",
        "for name, comp in compositions.items():",
        "    non_canonical = {k: v for k, v in comp.items() if k not in ['A', 'U', 'G', 'C']}",
        "    if non_canonical:",
        "        print(f\"  {name}: {non_canonical}\")",
        "    else:",
        "        print(f\"  {name}: Aucun\")",
        ""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.4 Distribution temporelle (temporal_cutoff)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Convertir les dates",
        "train_sequences['temporal_cutoff'] = pd.to_datetime(train_sequences['temporal_cutoff'])",
        "validation_sequences['temporal_cutoff'] = pd.to_datetime(validation_sequences['temporal_cutoff'])",
        "",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))",
        "",
        "# Train",
        "train_sequences.groupby(train_sequences['temporal_cutoff'].dt.to_period('M')).size().plot(",
        "    kind='bar', ax=axes[0], color='steelblue', alpha=0.7",
        ")",
        "axes[0].set_title('Train - Distribution temporelle', fontsize=12, fontweight='bold')",
        "axes[0].set_xlabel('Date de publication')",
        "axes[0].set_ylabel('Nombre de structures')",
        "axes[0].tick_params(axis='x', rotation=45)",
        "",
        "# Validation",
        "validation_sequences.groupby(validation_sequences['temporal_cutoff'].dt.to_period('M')).size().plot(",
        "    kind='bar', ax=axes[1], color='seagreen', alpha=0.7",
        ")",
        "axes[1].set_title('Validation - Distribution temporelle', fontsize=12, fontweight='bold')",
        "axes[1].set_xlabel('Date de publication')",
        "axes[1].set_ylabel('Nombre de structures')",
        "axes[1].tick_params(axis='x', rotation=45)",
        "",
        "plt.suptitle('\ud83d\udcc5 Distribution Temporelle des Structures', fontsize=14, fontweight='bold', y=1.02)",
        "plt.tight_layout()",
        "plt.show()",
        "",
        "print(f\"\\n\ud83d\udcc5 Plages temporelles:\")",
        "print(f\"  Train:      {train_sequences['temporal_cutoff'].min().date()} \u2192 {train_sequences['temporal_cutoff'].max().date()}\")",
        "print(f\"  Validation: {validation_sequences['temporal_cutoff'].min().date()} \u2192 {validation_sequences['temporal_cutoff'].max().date()}\")",
        ""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.5 Analyse de la stoichiom\u00e9trie\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Analyser les patterns de stoichiom\u00e9trie",
        "def parse_stoichiometry(stoich_str):",
        "    \"\"\"Parse stoichiometry string to extract chain counts.\"\"\"",
        "    if pd.isna(stoich_str):",
        "        return {}",
        "    chains = {}",
        "    for part in stoich_str.split(';'):",
        "        if ':' in part:",
        "            chain, count = part.split(':')",
        "            chains[chain.strip()] = int(count)",
        "    return chains",
        "",
        "train_sequences['n_chains'] = train_sequences['stoichiometry'].apply(",
        "    lambda x: sum(parse_stoichiometry(x).values()) if pd.notna(x) else 0",
        ")",
        "validation_sequences['n_chains'] = validation_sequences['stoichiometry'].apply(",
        "    lambda x: sum(parse_stoichiometry(x).values()) if pd.notna(x) else 0",
        ")",
        "",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))",
        "",
        "# Distribution du nombre de cha\u00eenes",
        "for idx, (name, df, color) in enumerate([('Train', train_sequences, 'steelblue'),",
        "                                          ('Validation', validation_sequences, 'seagreen')]):",
        "    chain_counts = df['n_chains'].value_counts().sort_index()",
        "    axes[idx].bar(chain_counts.index, chain_counts.values, color=color, alpha=0.7, edgecolor='black')",
        "    axes[idx].set_title(f'{name} - Nombre de cha\u00eenes', fontsize=12, fontweight='bold')",
        "    axes[idx].set_xlabel('Nombre de cha\u00eenes')",
        "    axes[idx].set_ylabel('Fr\u00e9quence')",
        "",
        "plt.suptitle('\ud83d\udd17 Distribution du Nombre de Cha\u00eenes par Structure', fontsize=14, fontweight='bold', y=1.02)",
        "plt.tight_layout()",
        "plt.show()",
        "",
        "print(\"\\n\ud83d\udcca Statistiques sur les cha\u00eenes:\")",
        "print(f\"  Train - Moyenne: {train_sequences['n_chains'].mean():.2f}, Max: {train_sequences['n_chains'].max()}\")",
        "print(f\"  Validation - Moyenne: {validation_sequences['n_chains'].mean():.2f}, Max: {validation_sequences['n_chains'].max()}\")",
        ""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud83c\udfaf 4. Analyse des Labels (Coordonn\u00e9es 3D)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Structure des labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"\ud83d\udccb Colonnes train_labels:\")\n",
        "print(train_labels.columns.tolist())\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "train_labels.head(10)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Nombre de structures alternatives par cible",
        "coord_cols = [c for c in train_labels.columns if c.startswith('x_')]",
        "n_structures = len(coord_cols)",
        "print(f\"\\n\ud83d\udd39 Nombre de structures alternatives dans train_labels: {n_structures}\")",
        "print(f\"   Colonnes de coordonn\u00e9es: {coord_cols}\")",
        "",
        "# V\u00e9rifier les valeurs manquantes",
        "print(f\"\\n\ud83d\udd39 Valeurs manquantes dans les coordonn\u00e9es:\")",
        "for col in ['x_1', 'y_1', 'z_1']:",
        "    missing = train_labels[col].isna().sum()",
        "    print(f\"   {col}: {missing:,} ({missing/len(train_labels)*100:.2f}%)\")",
        ""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Distribution des r\u00e9sidus par structure\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Compter les r\u00e9sidus par target_id",
        "train_labels['target_id'] = train_labels['ID'].str.rsplit('_', n=1).str[0]",
        "residues_per_target = train_labels.groupby('target_id').size()",
        "",
        "fig, ax = plt.subplots(figsize=(12, 5))",
        "ax.hist(residues_per_target, bins=50, color='purple', alpha=0.7, edgecolor='black')",
        "ax.set_title('Distribution du Nombre de R\u00e9sidus par Structure', fontsize=12, fontweight='bold')",
        "ax.set_xlabel('Nombre de r\u00e9sidus')",
        "ax.set_ylabel('Fr\u00e9quence')",
        "ax.axvline(residues_per_target.median(), color='red', linestyle='--',",
        "           label=f\"M\u00e9diane: {residues_per_target.median():.0f}\")",
        "ax.legend()",
        "plt.tight_layout()",
        "plt.show()",
        "",
        "print(f\"\\n\ud83d\udcc8 Statistiques des r\u00e9sidus par structure:\")",
        "print(f\"   Min: {residues_per_target.min()}, Max: {residues_per_target.max()}\")",
        "print(f\"   Mean: {residues_per_target.mean():.1f}, Median: {residues_per_target.median():.0f}\")",
        ""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Distribution des types de r\u00e9sidus\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))",
        "",
        "for idx, (name, df, color) in enumerate([('Train', train_labels, 'steelblue'),",
        "                                          ('Validation', validation_labels, 'seagreen')]):",
        "    resname_counts = df['resname'].value_counts()",
        "    colors = [NUCLEOTIDE_COLORS.get(nt, 'gray') for nt in resname_counts.index]",
        "",
        "    bars = axes[idx].bar(resname_counts.index, resname_counts.values, color=colors, edgecolor='black')",
        "    axes[idx].set_title(f'{name} - Distribution des r\u00e9sidus', fontsize=12, fontweight='bold')",
        "    axes[idx].set_xlabel('Type de r\u00e9sidu')",
        "    axes[idx].set_ylabel('Fr\u00e9quence')",
        "",
        "    # Ajouter pourcentages",
        "    total = resname_counts.sum()",
        "    for bar, val in zip(bars, resname_counts.values):",
        "        pct = val / total * 100",
        "        axes[idx].text(bar.get_x() + bar.get_width()/2, bar.get_height() + total*0.01,",
        "                      f'{pct:.1f}%', ha='center', fontsize=9)",
        "",
        "plt.suptitle('\ud83e\uddec Distribution des Types de R\u00e9sidus', fontsize=14, fontweight='bold', y=1.02)",
        "plt.tight_layout()",
        "plt.show()",
        ""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.4 Distribution spatiale des coordonn\u00e9es\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# \u00c9chantillonner pour la visualisation",
        "sample_labels = train_labels.dropna(subset=['x_1', 'y_1', 'z_1']).sample(min(50000, len(train_labels)))",
        "",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))",
        "",
        "for idx, (coord, color) in enumerate([('x_1', 'red'), ('y_1', 'green'), ('z_1', 'blue')]):",
        "    axes[idx].hist(sample_labels[coord], bins=50, color=color, alpha=0.7, edgecolor='black')",
        "    axes[idx].set_title(f'Distribution {coord.upper()}', fontsize=12, fontweight='bold')",
        "    axes[idx].set_xlabel(f'{coord} (\u00c5ngstr\u00f6ms)')",
        "    axes[idx].set_ylabel('Fr\u00e9quence')",
        "",
        "    mean_val = sample_labels[coord].mean()",
        "    axes[idx].axvline(mean_val, color='black', linestyle='--', label=f'Mean: {mean_val:.1f}\u00c5')",
        "    axes[idx].legend()",
        "",
        "plt.suptitle('\ud83d\udcd0 Distribution Spatiale des Coordonn\u00e9es C1\\'', fontsize=14, fontweight='bold', y=1.02)",
        "plt.tight_layout()",
        "plt.show()",
        ""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud83c\udf10 5. Visualisation 3D des Structures RNA\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.1 Fonction de visualisation 3D\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def visualize_rna_3d(labels_df, target_id, structure_idx=1, title=None):",
        "    \"\"\"",
        "    Visualise une structure RNA en 3D avec Plotly.",
        "",
        "    Args:",
        "        labels_df: DataFrame des labels",
        "        target_id: ID de la cible \u00e0 visualiser",
        "        structure_idx: Index de la structure (1, 2, etc.)",
        "        title: Titre personnalis\u00e9",
        "    \"\"\"",
        "    # Filtrer pour cette cible",
        "    target_data = labels_df[labels_df['ID'].str.startswith(target_id + '_')].copy()",
        "    target_data = target_data.sort_values('resid')",
        "",
        "    # Colonnes de coordonn\u00e9es",
        "    x_col, y_col, z_col = f'x_{structure_idx}', f'y_{structure_idx}', f'z_{structure_idx}'",
        "",
        "    # V\u00e9rifier que les colonnes existent",
        "    if x_col not in target_data.columns:",
        "        print(f\"Structure {structure_idx} non disponible pour {target_id}\")",
        "        return None",
        "",
        "    # Retirer les valeurs manquantes",
        "    target_data = target_data.dropna(subset=[x_col, y_col, z_col])",
        "",
        "    if len(target_data) == 0:",
        "        print(f\"Pas de donn\u00e9es pour {target_id}\")",
        "        return None",
        "",
        "    # Couleurs par nucl\u00e9otide",
        "    colors = [NUCLEOTIDE_COLORS.get(res, 'gray') for res in target_data['resname']]",
        "",
        "    # Cr\u00e9er la figure",
        "    fig = go.Figure()",
        "",
        "    # Ajouter la trace du backbone (ligne)",
        "    fig.add_trace(go.Scatter3d(",
        "        x=target_data[x_col],",
        "        y=target_data[y_col],",
        "        z=target_data[z_col],",
        "        mode='lines',",
        "        line=dict(color='lightgray', width=3),",
        "        name='Backbone',",
        "        hoverinfo='skip'",
        "    ))",
        "",
        "    # Ajouter les points (atomes C1')",
        "    fig.add_trace(go.Scatter3d(",
        "        x=target_data[x_col],",
        "        y=target_data[y_col],",
        "        z=target_data[z_col],",
        "        mode='markers',",
        "        marker=dict(",
        "            size=6,",
        "            color=colors,",
        "            opacity=0.9,",
        "            line=dict(color='black', width=0.5)",
        "        ),",
        "        text=[f\"Res {row['resid']}: {row['resname']}<br>({row[x_col]:.2f}, {row[y_col]:.2f}, {row[z_col]:.2f})\"",
        "              for _, row in target_data.iterrows()],",
        "        hoverinfo='text',",
        "        name=\"R\u00e9sidus C1'\"",
        "    ))",
        "",
        "    # Mise en page",
        "    title_text = title or f\"Structure 3D: {target_id} (n={len(target_data)} r\u00e9sidus)\"",
        "    fig.update_layout(",
        "        title=dict(text=title_text, font=dict(size=16)),",
        "        scene=dict(",
        "            xaxis_title='X (\u00c5)',",
        "            yaxis_title='Y (\u00c5)',",
        "            zaxis_title='Z (\u00c5)',",
        "            aspectmode='data'",
        "        ),",
        "        width=800,",
        "        height=600,",
        "        showlegend=True,",
        "        legend=dict(x=0.02, y=0.98)",
        "    )",
        "",
        "    # Ajouter l\u00e9gende des couleurs",
        "    for nt, color in NUCLEOTIDE_COLORS.items():",
        "        fig.add_trace(go.Scatter3d(",
        "            x=[None], y=[None], z=[None],",
        "            mode='markers',",
        "            marker=dict(size=10, color=color),",
        "            name=f'{nt}',",
        "            showlegend=True",
        "        ))",
        "",
        "    return fig",
        ""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 Visualisation de structures exemple\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# S\u00e9lectionner quelques structures int\u00e9ressantes\n",
        "target_ids = train_labels['ID'].str.rsplit('_', n=1).str[0].unique()\n",
        "\n",
        "# Trouver des structures de diff\u00e9rentes tailles\n",
        "sizes = train_labels.groupby(train_labels['ID'].str.rsplit('_', n=1).str[0]).size()\n",
        "small_target = sizes[sizes < 50].index[0] if len(sizes[sizes < 50]) > 0 else sizes.index[0]\n",
        "medium_target = sizes[(sizes >= 50) & (sizes < 150)].index[0] if len(sizes[(sizes >= 50) & (sizes < 150)]) > 0 else sizes.index[1]\n",
        "large_target = sizes[sizes >= 150].index[0] if len(sizes[sizes >= 150]) > 0 else sizes.index[2]\n",
        "\n",
        "print(f\"\ud83d\udd0d Structures s\u00e9lectionn\u00e9es pour visualisation:\")\n",
        "print(f\"   Petite:  {small_target} ({sizes[small_target]} r\u00e9sidus)\")\n",
        "print(f\"   Moyenne: {medium_target} ({sizes[medium_target]} r\u00e9sidus)\")\n",
        "print(f\"   Grande:  {large_target} ({sizes[large_target]} r\u00e9sidus)\")\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualiser une petite structure\n",
        "fig = visualize_rna_3d(train_labels, small_target)\n",
        "if fig:\n",
        "    fig.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualiser une structure moyenne\n",
        "fig = visualize_rna_3d(train_labels, medium_target)\n",
        "if fig:\n",
        "    fig.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualiser une grande structure",
        "fig = visualize_rna_3d(train_labels, large_target)",
        "if fig:",
        "    fig.show()",
        ""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.3 Comparaison de structures alternatives (si disponibles)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def compare_structures(labels_df, target_id, n_structures=2):",
        "    \"\"\"Compare plusieurs structures alternatives pour une m\u00eame cible.\"\"\"",
        "    target_data = labels_df[labels_df['ID'].str.startswith(target_id + '_')].copy()",
        "    target_data = target_data.sort_values('resid')",
        "",
        "    # V\u00e9rifier combien de structures sont disponibles",
        "    x_cols = [c for c in target_data.columns if c.startswith('x_')]",
        "    n_available = len(x_cols)",
        "",
        "    if n_available < 2:",
        "        print(f\"Seulement {n_available} structure(s) disponible(s) pour {target_id}\")",
        "        return None",
        "",
        "    n_to_show = min(n_structures, n_available)",
        "",
        "    fig = go.Figure()",
        "    colors = ['blue', 'red', 'green', 'orange', 'purple']",
        "",
        "    for i in range(1, n_to_show + 1):",
        "        x_col, y_col, z_col = f'x_{i}', f'y_{i}', f'z_{i}'",
        "        data = target_data.dropna(subset=[x_col, y_col, z_col])",
        "",
        "        if len(data) > 0:",
        "            fig.add_trace(go.Scatter3d(",
        "                x=data[x_col],",
        "                y=data[y_col],",
        "                z=data[z_col],",
        "                mode='lines+markers',",
        "                marker=dict(size=4, opacity=0.7),",
        "                line=dict(width=2),",
        "                name=f'Structure {i}',",
        "                marker_color=colors[i-1]",
        "            ))",
        "",
        "    fig.update_layout(",
        "        title=f\"Comparaison des structures: {target_id}\",",
        "        scene=dict(",
        "            xaxis_title='X (\u00c5)',",
        "            yaxis_title='Y (\u00c5)',",
        "            zaxis_title='Z (\u00c5)',",
        "            aspectmode='data'",
        "        ),",
        "        width=800,",
        "        height=600",
        "    )",
        "",
        "    return fig",
        "",
        "# Trouver une cible avec plusieurs structures",
        "multi_struct_cols = [c for c in train_labels.columns if c.startswith('x_')]",
        "if len(multi_struct_cols) > 1:",
        "    # V\u00e9rifier quelles cibles ont plusieurs conformations",
        "    sample_target = train_labels['ID'].str.rsplit('_', n=1).str[0].iloc[0]",
        "    fig = compare_structures(train_labels, sample_target)",
        "    if fig:",
        "        fig.show()",
        ""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.4 Analyse des distances inter-r\u00e9sidus\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def analyze_distances(labels_df, target_id, structure_idx=1):",
        "    \"\"\"Analyse les distances entre r\u00e9sidus cons\u00e9cutifs.\"\"\"",
        "    target_data = labels_df[labels_df['ID'].str.startswith(target_id + '_')].copy()",
        "    target_data = target_data.sort_values('resid')",
        "",
        "    x_col, y_col, z_col = f'x_{structure_idx}', f'y_{structure_idx}', f'z_{structure_idx}'",
        "    target_data = target_data.dropna(subset=[x_col, y_col, z_col])",
        "",
        "    if len(target_data) < 2:",
        "        return None",
        "",
        "    # Calculer les distances cons\u00e9cutives",
        "    coords = target_data[[x_col, y_col, z_col]].values",
        "    distances = np.sqrt(np.sum(np.diff(coords, axis=0)**2, axis=1))",
        "",
        "    return distances",
        "",
        "# Calculer pour plusieurs structures",
        "all_distances = []",
        "sample_targets = train_labels['ID'].str.rsplit('_', n=1).str[0].unique()[:100]",
        "",
        "for target in sample_targets:",
        "    distances = analyze_distances(train_labels, target)",
        "    if distances is not None:",
        "        all_distances.extend(distances)",
        "",
        "all_distances = np.array(all_distances)",
        "",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))",
        "",
        "# Histogramme",
        "axes[0].hist(all_distances, bins=50, color='purple', alpha=0.7, edgecolor='black')",
        "axes[0].set_title('Distribution des Distances C1\\'-C1\\' Cons\u00e9cutives', fontsize=12, fontweight='bold')",
        "axes[0].set_xlabel('Distance (\u00c5)')",
        "axes[0].set_ylabel('Fr\u00e9quence')",
        "axes[0].axvline(np.median(all_distances), color='red', linestyle='--',",
        "                label=f'M\u00e9diane: {np.median(all_distances):.2f}\u00c5')",
        "axes[0].legend()",
        "",
        "# Box plot",
        "axes[1].boxplot(all_distances, vert=True)",
        "axes[1].set_title('Box Plot des Distances', fontsize=12, fontweight='bold')",
        "axes[1].set_ylabel('Distance (\u00c5)')",
        "",
        "plt.suptitle('\ud83d\udccf Analyse des Distances Inter-R\u00e9sidus', fontsize=14, fontweight='bold', y=1.02)",
        "plt.tight_layout()",
        "plt.show()",
        "",
        "print(f\"\\n\ud83d\udcca Statistiques des distances C1'-C1' cons\u00e9cutives:\")",
        "print(f\"   Mean: {np.mean(all_distances):.2f}\u00c5\")",
        "print(f\"   Median: {np.median(all_distances):.2f}\u00c5\")",
        "print(f\"   Std: {np.std(all_distances):.2f}\u00c5\")",
        "print(f\"   Min: {np.min(all_distances):.2f}\u00c5, Max: {np.max(all_distances):.2f}\u00c5\")",
        ""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcc2 6. Analyse des MSA (Multiple Sequence Alignments)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def analyze_msa(msa_path, n_samples=5):\n",
        "    \"\"\"Analyse un fichier MSA.\"\"\"\n",
        "    try:\n",
        "        sequences = list(SeqIO.parse(msa_path, 'fasta'))\n",
        "\n",
        "        info = {\n",
        "            'n_sequences': len(sequences),\n",
        "            'target_length': len(sequences[0].seq) if sequences else 0,\n",
        "            'headers': [seq.id for seq in sequences[:n_samples]]\n",
        "        }\n",
        "\n",
        "        return info\n",
        "    except Exception as e:\n",
        "        return {'error': str(e)}\n",
        "\n",
        "# Analyser quelques MSA\n",
        "msa_dir = DATA_PATH / 'MSA'\n",
        "msa_files = list(msa_dir.glob('*.fasta'))[:10]\n",
        "\n",
        "print(f\"\ud83d\udcc1 Analyse de {len(msa_files)} fichiers MSA (sur {len(list(msa_dir.glob('*.fasta')))} total):\\n\")\n",
        "\n",
        "msa_stats = []\n",
        "for msa_file in msa_files:\n",
        "    info = analyze_msa(msa_file)\n",
        "    msa_stats.append({\n",
        "        'file': msa_file.name,\n",
        "        'n_sequences': info.get('n_sequences', 0),\n",
        "        'target_length': info.get('target_length', 0)\n",
        "    })\n",
        "    print(f\"  {msa_file.name}: {info.get('n_sequences', 'N/A')} s\u00e9quences, longueur {info.get('target_length', 'N/A')}\")\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Distribution de la profondeur des MSA",
        "all_msa_files = list(msa_dir.glob('*.fasta'))",
        "msa_depths = []",
        "",
        "print(f\"\\n\u23f3 Analyse de la profondeur des MSA ({len(all_msa_files)} fichiers)...\")",
        "",
        "for i, msa_file in enumerate(all_msa_files[:500]):  # Limiter pour la vitesse",
        "    try:",
        "        n_seqs = sum(1 for _ in SeqIO.parse(msa_file, 'fasta'))",
        "        msa_depths.append(n_seqs)",
        "    except:",
        "        pass",
        "",
        "fig, ax = plt.subplots(figsize=(10, 5))",
        "ax.hist(msa_depths, bins=50, color='teal', alpha=0.7, edgecolor='black')",
        "ax.set_title('Distribution de la Profondeur des MSA', fontsize=12, fontweight='bold')",
        "ax.set_xlabel('Nombre de s\u00e9quences dans le MSA')",
        "ax.set_ylabel('Fr\u00e9quence')",
        "ax.axvline(np.median(msa_depths), color='red', linestyle='--', label=f'M\u00e9diane: {np.median(msa_depths):.0f}')",
        "ax.legend()",
        "plt.tight_layout()",
        "plt.show()",
        "",
        "print(f\"\\n\ud83d\udcca Statistiques de profondeur MSA:\")",
        "print(f\"   Min: {np.min(msa_depths)}, Max: {np.max(msa_depths)}\")",
        "print(f\"   Mean: {np.mean(msa_depths):.1f}, Median: {np.median(msa_depths):.0f}\")",
        ""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udccb 7. Analyse des M\u00e9tadonn\u00e9es\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"\ud83d\udccb Colonnes rna_metadata:\")\n",
        "print(rna_metadata.columns.tolist())\n",
        "print(f\"\\nShape: {rna_metadata.shape}\")\n",
        "rna_metadata.head()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Analyse des colonnes cl\u00e9s",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))",
        "",
        "# Resolution",
        "if 'resolution' in rna_metadata.columns:",
        "    rna_metadata['resolution'].dropna().hist(bins=50, ax=axes[0, 0], color='steelblue', alpha=0.7)",
        "    axes[0, 0].set_title('Distribution de la R\u00e9solution', fontsize=11, fontweight='bold')",
        "    axes[0, 0].set_xlabel('R\u00e9solution (\u00c5)')",
        "",
        "# Method",
        "if 'method' in rna_metadata.columns:",
        "    method_counts = rna_metadata['method'].value_counts().head(10)",
        "    method_counts.plot(kind='barh', ax=axes[0, 1], color='seagreen', alpha=0.7)",
        "    axes[0, 1].set_title('M\u00e9thodes Exp\u00e9rimentales', fontsize=11, fontweight='bold')",
        "    axes[0, 1].set_xlabel('Nombre de structures')",
        "",
        "# RNA composition",
        "if 'rna_composition' in rna_metadata.columns:",
        "    rna_metadata['rna_composition'].dropna().hist(bins=50, ax=axes[1, 0], color='coral', alpha=0.7)",
        "    axes[1, 0].set_title('Composition RNA (%)', fontsize=11, fontweight='bold')",
        "    axes[1, 0].set_xlabel('% RNA')",
        "",
        "# Structuredness",
        "if 'structuredness' in rna_metadata.columns:",
        "    rna_metadata['structuredness'].dropna().hist(bins=50, ax=axes[1, 1], color='purple', alpha=0.7)",
        "    axes[1, 1].set_title('Structuredness', fontsize=11, fontweight='bold')",
        "    axes[1, 1].set_xlabel('Structuredness score')",
        "",
        "plt.suptitle('\ud83d\udcca Analyse des M\u00e9tadonn\u00e9es RNA', fontsize=14, fontweight='bold', y=1.02)",
        "plt.tight_layout()",
        "plt.show()",
        ""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcdd 8. Analyse du Format de Soumission\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"\ud83d\udccb Format de soumission:\")\n",
        "print(sample_submission.columns.tolist())\n",
        "print(f\"\\nShape: {sample_submission.shape}\")\n",
        "sample_submission.head(10)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# V\u00e9rifier le nombre de pr\u00e9dictions requises",
        "coord_cols = [c for c in sample_submission.columns if c.startswith('x_')]",
        "print(f\"\\n\ud83c\udfaf Nombre de structures \u00e0 pr\u00e9dire: {len(coord_cols)} (x_1 \u00e0 x_{len(coord_cols)})\")",
        "",
        "# Nombre de cibles uniques dans le test",
        "test_target_ids = sample_submission['ID'].str.rsplit('_', n=1).str[0].unique()",
        "print(f\"\ud83d\udcca Nombre de cibles test: {len(test_target_ids)}\")",
        "print(f\"\ud83d\udcca Nombre total de r\u00e9sidus \u00e0 pr\u00e9dire: {len(sample_submission)}\")",
        ""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83c\udfaf 9. R\u00e9sum\u00e9 et Insights Cl\u00e9s\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"                    \ud83d\udcca R\u00c9SUM\u00c9 DE L'ANALYSE EDA\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\"\"\n",
        "\ud83d\udd39 DONN\u00c9ES:\n",
        "   \u2022 Train: {train_seq} s\u00e9quences, {train_res:,} r\u00e9sidus\n",
        "   \u2022 Validation: {val_seq} s\u00e9quences, {val_res:,} r\u00e9sidus\n",
        "   \u2022 Test: {test_seq} s\u00e9quences \u00e0 pr\u00e9dire\n",
        "   \u2022 MSA disponibles: {msa_count:,} fichiers\n",
        "   \u2022 Structures PDB: {pdb_count:,} fichiers\n",
        "\n",
        "\ud83d\udd39 S\u00c9QUENCES:\n",
        "   \u2022 Longueur m\u00e9diane: Train={train_med:.0f}, Val={val_med:.0f}, Test={test_med:.0f}\n",
        "   \u2022 Composition: ~25% chaque nucl\u00e9otide (A, U, G, C \u00e9quilibr\u00e9s)\n",
        "   \u2022 Structures multi-cha\u00eenes pr\u00e9sentes\n",
        "\n",
        "\ud83d\udd39 STRUCTURES 3D:\n",
        "   \u2022 Coordonn\u00e9es: Position de l'atome C1' de chaque r\u00e9sidu\n",
        "   \u2022 Distance C1'-C1' cons\u00e9cutive: ~{dist_mean:.1f}\u00c5 (m\u00e9diane)\n",
        "   \u2022 Format soumission: 5 structures par cible\n",
        "\n",
        "\ud83d\udd39 INSIGHTS POUR LA MOD\u00c9LISATION:\n",
        "   \u2022 Les MSA profonds peuvent aider (info \u00e9volutive)\n",
        "   \u2022 Templates PDB disponibles pour recherche d'homologues\n",
        "   \u2022 Validation temporelle: structures apr\u00e8s mai 2025\n",
        "   \u2022 M\u00e9trique: TM-score (best of 5 predictions)\n",
        "\"\"\".format(\n",
        "    train_seq=len(train_sequences),\n",
        "    train_res=len(train_labels),\n",
        "    val_seq=len(validation_sequences),\n",
        "    val_res=len(validation_labels),\n",
        "    test_seq=len(test_sequences),\n",
        "    msa_count=len(list((DATA_PATH / 'MSA').glob('*.fasta'))),\n",
        "    pdb_count=len(list((DATA_PATH / 'PDB_RNA').glob('*.cif'))),\n",
        "    train_med=train_sequences['seq_length'].median(),\n",
        "    val_med=validation_sequences['seq_length'].median(),\n",
        "    test_med=test_sequences['seq_length'].median(),\n",
        "    dist_mean=np.median(all_distances) if len(all_distances) > 0 else 5.9\n",
        "))\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"                    \ud83d\ude80 PR\u00caT POUR LA MOD\u00c9LISATION!\")\n",
        "print(\"=\" * 70)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ]
}
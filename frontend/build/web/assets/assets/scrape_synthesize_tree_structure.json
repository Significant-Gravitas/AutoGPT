{
    "edges": [
        {
            "arrows": "to",
            "from": "agbenchmark/generate_test.py::TestReadFile::test_method[challenge_data0]",
            "id": "agbenchmark/generate_test.py::TestReadFile::test_method[challenge_data0]_to_agbenchmark/generate_test.py::TestSynthesizeInfo::test_method[challenge_data0]",
            "to": "agbenchmark/generate_test.py::TestSynthesizeInfo::test_method[challenge_data0]"
        },
        {
            "arrows": "to",
            "from": "agbenchmark/generate_test.py::TestWriteFile::test_method[challenge_data0]",
            "id": "agbenchmark/generate_test.py::TestWriteFile::test_method[challenge_data0]_to_agbenchmark/generate_test.py::TestReadFile::test_method[challenge_data0]",
            "to": "agbenchmark/generate_test.py::TestReadFile::test_method[challenge_data0]"
        }
    ],
    "nodes": [
        {
            "color": "grey",
            "data": {
                "category": [
                    "scrape_synthesize"
                ],
                "cutoff": 240,
                "dependencies": [
                    "TestReadFile"
                ],
                "eval_id": "76e4c56c-8d57-423e-9cc1-1fff5f58dee6",
                "ground": {
                    "answer": "A report highlighting elements from the 2 files.",
                    "eval": {
                        "scoring": "binary",
                        "template": "question",
                        "type": "llm"
                    },
                    "files": [
                        "output.txt"
                    ],
                    "should_contain": [
                        "Is the company mentioned in the output actively addressing or capitalizing on the challenges or trends listed?"
                    ],
                    "should_not_contain": []
                },
                "info": {
                    "description": "Tests ability to generate content based on the content of 2 files.",
                    "difficulty": "basic",
                    "side_effects": []
                },
                "name": "TestSynthesizeInfo",
                "task": "Create a brief report or summary highlighting how one or more companies from companies.txt are addressing or capitalizing on challenges or trends from challenges.txt. Write a file called output.txt."
            },
            "id": "agbenchmark/generate_test.py::TestSynthesizeInfo::test_method[challenge_data0]",
            "label": "SynthesizeInfo",
            "shape": "dot"
        },
        {
            "color": "grey",
            "data": {
                "category": [
                    "interface"
                ],
                "cutoff": 60,
                "dependencies": [
                    "TestWriteFile"
                ],
                "eval_id": "261ccfaa-02a2-4c1a-8a56-c76c66f7dba1",
                "ground": {
                    "answer": "The content of output.txt should be 'Hello World!'",
                    "eval": {
                        "type": "file"
                    },
                    "files": [
                        "output.txt"
                    ],
                    "should_contain": [
                        "Hello World!"
                    ]
                },
                "info": {
                    "description": "tests the ability for an agent to read a file.",
                    "difficulty": "interface",
                    "side_effects": [
                        ""
                    ]
                },
                "name": "TestReadFile",
                "task": "Read the file called file_to_read.txt and write its content to a file called output.txt"
            },
            "id": "agbenchmark/generate_test.py::TestReadFile::test_method[challenge_data0]",
            "label": "ReadFile",
            "shape": "dot"
        },
        {
            "color": "grey",
            "data": {
                "category": [
                    "interface"
                ],
                "cutoff": 60,
                "dependencies": [],
                "eval_id": "81b64bf9-2b6a-4ac8-bcd2-8bfe36244ac0",
                "ground": {
                    "answer": "The word 'Washington', printed to a .txt file named anything",
                    "eval": {
                        "type": "file"
                    },
                    "files": [
                        ".txt"
                    ],
                    "should_contain": [
                        "Washington"
                    ],
                    "should_not_contain": []
                },
                "info": {
                    "description": "Tests the agents ability to write to a file",
                    "difficulty": "interface",
                    "side_effects": [
                        ""
                    ]
                },
                "name": "TestWriteFile",
                "task": "Write the word 'Washington' to a .txt file"
            },
            "id": "agbenchmark/generate_test.py::TestWriteFile::test_method[challenge_data0]",
            "label": "WriteFile",
            "shape": "dot"
        }
    ]
}
